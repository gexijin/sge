<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.42.2" />
  <meta name="author" content="Steven Xijin Ge">

  
  
  
  
    
      
    
  
  <meta name="description" content="Spot instances on Amazon Elastic Compute Cloud (EC2) allows researchers to do high performance computing at very low cost. These are spare computing capacities that could be abruptly terminated. But such interruptions are rare, and can be tolerated in scientific research. For example, a 64-core workstation with 256 GB of memory can be rented at about $0.7 per hour, which is ~80% off regular on-demand prices. You can request 10 of such servers and use them for 5 days and 2 hours and it only cost you a few hundred dollars.">

  
  <link rel="alternate" hreflang="en-us" href="/post/using-amazon-ec2-to-run-large-data-analysis-cheaply/">

  


  

  
  
  <meta name="theme-color" content="#0095eb">
  
  
  
  
    
  
  
    
    
      
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
      
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-87863704-4', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="In Data We Trust">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="In Data We Trust">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/post/using-amazon-ec2-to-run-large-data-analysis-cheaply/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@StevenXGe">
  <meta property="twitter:creator" content="@StevenXGe">
  
  <meta property="og:site_name" content="In Data We Trust">
  <meta property="og:url" content="/post/using-amazon-ec2-to-run-large-data-analysis-cheaply/">
  <meta property="og:title" content="Using Amazon EC2 to run large data analyses cheaply | In Data We Trust">
  <meta property="og:description" content="Spot instances on Amazon Elastic Compute Cloud (EC2) allows researchers to do high performance computing at very low cost. These are spare computing capacities that could be abruptly terminated. But such interruptions are rare, and can be tolerated in scientific research. For example, a 64-core workstation with 256 GB of memory can be rented at about $0.7 per hour, which is ~80% off regular on-demand prices. You can request 10 of such servers and use them for 5 days and 2 hours and it only cost you a few hundred dollars.">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2018-07-05T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2018-07-05T00:00:00&#43;00:00">
  

  

  

  <title>Using Amazon EC2 to run large data analyses cheaply | In Data We Trust</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">In Data We Trust</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>About</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">Using Amazon EC2 to run large data analyses cheaply</h1>

    

<div class="article-metadata">

  

  <span class="article-date">
    
    <meta content="2018-07-05 00:00:00 &#43;0000 UTC" itemprop="datePublished">
    <time datetime="2018-07-05 00:00:00 &#43;0000 UTC" itemprop="dateModified">
      Jul 5, 2018
    </time>
  </span>
  <span itemscope itemprop="author publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Steven Xijin Ge">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    7 min read
  </span>
  

  
  
  <span class="middot-divider"></span>
  <a href="/post/using-amazon-ec2-to-run-large-data-analysis-cheaply/#disqus_thread"></a>
  

  
  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fa fa-folder"></i>
    
    <a href="/categories/cloud-computing/">cloud computing</a
    >
    
  </span>
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Using%20Amazon%20EC2%20to%20run%20large%20data%20analyses%20cheaply&amp;url=%2fpost%2fusing-amazon-ec2-to-run-large-data-analysis-cheaply%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fpost%2fusing-amazon-ec2-to-run-large-data-analysis-cheaply%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fpost%2fusing-amazon-ec2-to-run-large-data-analysis-cheaply%2f&amp;title=Using%20Amazon%20EC2%20to%20run%20large%20data%20analyses%20cheaply"
         target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fpost%2fusing-amazon-ec2-to-run-large-data-analysis-cheaply%2f&amp;title=Using%20Amazon%20EC2%20to%20run%20large%20data%20analyses%20cheaply"
         target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Using%20Amazon%20EC2%20to%20run%20large%20data%20analyses%20cheaply&amp;body=%2fpost%2fusing-amazon-ec2-to-run-large-data-analysis-cheaply%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


    <div class="article-style" itemprop="articleBody">
      

<p>Spot instances on Amazon Elastic Compute Cloud (EC2) allows researchers to do high performance computing at very low cost. These are spare computing capacities that could be abruptly terminated. But such interruptions are rare, and can be tolerated in scientific research.  For example, a 64-core workstation with 256 GB of memory can be rented at about $0.7 per hour, which is ~80% off regular on-demand prices. You can request 10 of such servers and use them for 5 days and 2 hours and it only cost you a few hundred dollars.</p>

<p>Here I document how I requested an instance (virtual machine) on Amazon EC2, established a connection via SSH, and configured the Linux machine to run R using Docker containers (also new to me). I know little about Linux and networking. If I can make it work, so can you. The instructions below may not be the best way to do things, as I do not understand a lot of the technical details.</p>

<h2 id="main-topics-covered-this-tutorial">Main topics covered this tutorial:</h2>

<ul>
<li>Set up Key Pairs and Security Groups to enable SHH login.</li>
<li>Request spot instance (virtual machine)</li>
<li>SHH access to the instance via Putty and Filezilla</li>
<li>Install Docker software so that we can easily configure a computing environment</li>
<li>Build a docker image based on the Bioconductor docker definition files and a few extra packages</li>
<li>Start R and compute from within the docker container</li>
<li>Create a &ldquo;volume&rdquo; (a virtual hard drive) and attach it to running instances.</li>
<li>Take a snapshot of a running instance, copy it across regions, and use it to create a volume.</li>
<li>Google Compute Engine set-up.</li>
</ul>

<h2 id="these-are-the-steps-i-took">These are the steps I took:</h2>

<ol>
<li>Create an account and sign in to Amazon EC2. You can use your Amazon account. You will need a credit card number.
<img src="/img/postEC2/image001.png" alt="EC2" /></li>
<li>Create a key pair using the menu on the left in the NETWORK &amp; SECURITY. A file named XXX.pem will be downloaded automatically. I called it key1.pem. This file will be needed to establish SHH connection later.
<img src="/img/postEC2/image003.png" alt="Keypair" /></li>
<li>Create a Security Group.  Under the NETWORK&amp; SECURITY, click on Security Groups and then choose Create Security Group.  Select SSH from the &ldquo;Type&rdquo; column.  The default outbound rule seems to work. We will use this Security Group when we specify our instances.
<img src="/img/postEC2/image005.png" alt="rert" /></li>
<li>Start requesting an instance (virtual machine) by clicking on the Spot Requests on the left. Instances initiated with Spot Requests are much cheaper than regular instances. They are computers at idle. They can be terminated abruptly though.
<img src="/img/postEC2/image007.png" alt="rert" /></li>
<li>Start the Spot Advisor and enter your request. Change the amount required to 1. Otherwise, 20 instances will be requested. A 64-core instance with 256GB memory costs $0.67 per hour or about $16 per day.  Note that Amazon has web servers all across the world. You can switch regions from the top right of the screen. Prices and availability of resources vary greatly across the region.
<img src="/img/postEC2/image009.png" alt="rert" /></li>
<li>Configure your instance

<ul>
<li>Choose Ubuntu Server 16.04</li>
<li>Increase EBS volumes to 20 GB from the default 8GB</li>
<li>Make sure the key pair you created (key1) is used.</li>
<li>Choose the SHH-enabled Security group we created.
<img src="/img/postEC2/image011.png" alt="rert" /></li>
</ul></li>
<li>Click Launch and wait a few minutes for Amazon to fulfill this request. Reasons for failed requests vary. There are limits on the maximum number of spot instances for a region such as us-east-2b. There are also limits on new users. These can be lifted by filing a request in the Support Center.
<img src="/img/postEC2/image013.png" alt="rert" /></li>
<li>Once fulfilled, the instance is listed under Instances.
<img src="/img/postEC2/image015.png" alt="image" /></li>
<li>To connect to the instance, click on the Connect button (above), information like this will be shown.
<img src="/img/postEC2/image017.png" alt="image" /></li>
<li>Download Puttygen.exe to convert the key1.pem we got from Amazon to a private key file, &ldquo;key1-Ec2.ppk&rdquo;.  <img src="/img/postEC2/image019.png" alt="image" /></li>
<li>Download and start Putty.exe

<ul>
<li>Copy and paste the public DNS, such as ec2-52-14-231-133.us-east-2.compute.amazonaws.com</li>
<li>Under Connection and Data, enter the user name: ubuntu or ec2-user</li>
<li>Under Connection -&gt; SSH  -&gt; Auth, upload the converted private key file &ldquo;key1-Ec2.ppk&rdquo;.</li>
<li>Save this session info as EC2-spot3, so that next time we can easily connect to this instances without going through a-c.
<img src="/img/postEC2/image021.png" alt="image" /></li>
</ul></li>
<li>We are connected to the instance!!!<br />
<img src="/img/postEC2/image023.png" alt="image" /></li>

<li><p>To copy files to this instance, use FileZilla and follow directions <a href="http://angus.readthedocs.io/en/2014/amazon/transfer-files-between-instance.html" target="_blank">here</a></p>

<ul>
<li>Go to Edit -&gt; Settings to add the key1.pem file as a security key</li>
<li>File -&gt; Site Manager -&gt; New Site:</li>
<li>Change Protocol to SFTP;  paste host name, Change Logon Type to Normal;  and enter the username &ldquo;ubuntu&rdquo;.</li>
<li>Alternatively, we can use scp:</li>
</ul>

<pre><code>scp -i ../key1.pem  animals.tar.gz     ubuntu@ec2-52-14-179-157.us-east-2.compute.amazonaws.com:/mnt/data/
</code></pre></li>

<li><p>Install Docker software follow this <a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/#install-using-the-repository" target="_blank">instruction</a>, summerized below:</p>

<pre><code>sudo apt-get update
sudo apt-get install \
    apt-transport-https \
    ca-certificates \
    curl \
    software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository \
   &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \
   $(lsb_release -cs) \
   stable&quot;
sudo apt-get update
sudo apt-get install docker-ce
</code></pre></li>

<li><p>Define your docker image. Save this  as a file called: Dockerfile in a folder such as /home/ubuntu/dockers/. See <a href="https://www.bioconductor.org/help/docker/" target="_blank">here for the Bioconductor docker</a></p>

<pre><code>FROM bioconductor/release_core2
RUN R -e 'source(&quot;https://bioconductor.org/biocLite.R&quot;);
biocLite(c(&quot;GO.db&quot;, &quot;GOstats&quot;), suppressUpdates = T)'
</code></pre></li>

<li><p>Create an image called mybioconductor. Navigate to the folder that contains the file named Dockerfile, and then</p>

<pre><code>sudo docker build -t mybioconductor  .
</code></pre></li>

<li><p>Create a data folder</p>

<pre><code>mkdir ~/data
</code></pre>

<p>18.Start Bioconductor Docker container instance called bio1. The /home/ubuntu/data folder visible in the docker container as /data</p>

<pre><code>sudo docker run -v /home/ubuntu/data:/data --name bio1 -t         mybioconductor 
</code></pre></li>

<li><p>Within the container, you now have the most recent R and Bioconductor. Note that you are logged in as root in the container with IDs like 9c4b9c5d1492.
<img src="/img/postEC2/image025.png" alt="image" /></p></li>

<li><p>To run large R jobs in the background use nohup</p>

<pre><code>nohup R CMD BATCH myScript.R &gt; nohup.out &amp; 
</code></pre></li>

<li><p>It is safe to exit the container. To go back to the container:</p>

<pre><code>sudo docker exec -it bio2 /bin/bash 
</code></pre></li>
</ol>

<p>The following steps are optional.</p>

<ol>
<li>Create a volume from Elastic Block Store on the menu bar of the EC2 interface.
Create volume in the exactly the same region such as us-east-2b. These storages will persist even if the instance is terminated.</li>
<li>Attach the volume to the instance.  Select the volume and attach to the desired instance</li>

<li><p>Mount the created volume to a folder /mnt. Note that the volume needs to be mounted again after reboot. <a href="https://n2ws.com/blog/how-to-guides/connect-aws-ebs-volume-another-instance" target="_blank">See here</a></p>

<pre><code>cd /
sudo mkdir mnt  # create a folder
sudo chmod -R a+rwX /mnt
lsblk    # check the list of devices 
sudo mkfs.ext4 /dev/xvdf      # create a file system
sudo mount /dev/xvdf  /mnt 
</code></pre></li>

<li><p>Snapshots can be created from the running instances. This snapshot can be copied across regions (Ohio to Central). We can also create a volume based on the snapshot and access the data. To mount volumes created from snapshots. Note that file system already exists on the volumes created from snapshots. We should be mounting the xvdf1, not xvdf. <a href="https://serverfault.com/questions/632905/cannot-mount-an-existing-ebs-on-aws" target="_blank">Details</a></p>

<pre><code>cd /
sudo mkdir mnt  # create folder
lsblk    # check the list of devices 
sudo mount /dev/xvdf1  /mnt      
sudo chmod -R a+rwX /mnt    # make folder writable to all
</code></pre></li>

<li><p>Google Compute Engine can be set up following a similar fashion following <a href="https://www.onepagezen.com/google-cloud-ftp-filezilla-quick-start/" target="_blank">instructions</a></p>

<ul>
<li>Login and create instance at Google  Compute Engine</li>
<li>Download PuttyGen</li>
<li>click Generate to create key pairs</li>
<li>Save private key file</li>
<li>Copy the public key to clipboard</li>
<li>Click Metadata in Compute Engine menu and add SHH Key by paste the public key</li>
<li>Filezella &ndash;&gt; Edit &ndash;&gt; settings &ndash;&gt; SFTP  &ndash;&gt; Add key file</li>
</ul></li>
</ol>

<p>Following these step, I was able to create 3 fairly powerful servers, each with 64 cores, 256GB memory and 50GB SSD. Using the foreach and doSNOW  R packages, we can use all the cores in parallel at 100%.  I shut them down when all finished in a few days. It costed less than $200. Yes, the flexibility and affordability of computing are here. It is less complicated than you think.</p>

<p>Please let me know if you have any comments or suggestions.</p>

<p>Note: This was intially a note for myself taken using OneNote. Translating to Markdown is such a painful process. It remained me of the early days Fortran programming. Counting spaces&hellip; Someone simplify it! I need to figure out a way to insert a html file directly into Blogdown as a post.</p>

    </div>

    


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="/tags/amazon-ec2/">Amazon EC2</a>
  
</div>




    
    

    

    
<section id="comments">
  <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "https-gex-netlify-com" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>



  </div>
</article>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2018 &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    <script id="dsq-count-scr" src="//https-gex-netlify-com.disqus.com/count.js" async></script>
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    

  </body>
</html>

